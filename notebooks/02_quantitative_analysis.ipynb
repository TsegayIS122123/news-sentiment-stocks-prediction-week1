{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e05adc1",
   "metadata": {},
   "source": [
    "# Task 2: Quantitative Analysis with PyNance and TA-Lib\n",
    "\n",
    "## Objective:\n",
    "Perform quantitative financial analysis using technical indicators and financial metrics to understand stock price movements and create professional trading visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d359854",
   "metadata": {},
   "source": [
    "1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53fdb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "print(\" Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1509b6",
   "metadata": {},
   "source": [
    "2. LOAD STOCK PRICE DATA FROM CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba9ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LOADING ALL STOCK DATA FILES\n",
      "=============================================\n",
      "Found 6 stock files in ../data/Data/:\n",
      "  • AAPL.csv\n",
      "  • AMZN.csv\n",
      "  • GOOG.csv\n",
      "  • META.csv\n",
      "  • MSFT.csv\n",
      "  • NVDA.csv\n",
      " AAPL: 3,774 rows loaded\n",
      " AMZN: 3,774 rows loaded\n",
      " GOOG: 3,774 rows loaded\n",
      " META: 2,923 rows loaded\n",
      " MSFT: 3,774 rows loaded\n",
      " NVDA: 3,774 rows loaded\n",
      "\n",
      " SUMMARY: Successfully loaded 6 stocks\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD ALL STOCK DATA FILES\n",
    "# =============================================================================\n",
    "\n",
    "print(\" LOADING ALL STOCK DATA FILES\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Define the data path\n",
    "data_path = '../data/Data/'\n",
    "\n",
    "# List all files in the Data directory\n",
    "try:\n",
    "    stock_files = os.listdir(data_path)\n",
    "    print(f\"Found {len(stock_files)} stock files in {data_path}:\")\n",
    "    for file in stock_files:\n",
    "        print(f\"  • {file}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\" Error: Directory {data_path} not found\")\n",
    "    stock_files = []\n",
    "\n",
    "# Load each stock file into a DataFrame\n",
    "stock_data = {}\n",
    "for stock_file in stock_files:\n",
    "    if stock_file.endswith('.csv'):\n",
    "        stock_name = stock_file.replace('.csv', '')  # Remove .csv extension\n",
    "        file_path = os.path.join(data_path, stock_file)\n",
    "        \n",
    "        try:\n",
    "            # Load the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            stock_data[stock_name] = df\n",
    "            print(f\" {stock_name}: {len(df):,} rows loaded\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error loading {stock_file}: {e}\")\n",
    "\n",
    "print(f\"\\n SUMMARY: Successfully loaded {len(stock_data)} stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edac0a5",
   "metadata": {},
   "source": [
    "3. CHECK REQUIRED COLUMNS FOR ALL STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4469071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHECKING REQUIRED COLUMNS FOR ALL STOCKS\n",
      "=======================================================\n",
      "Required columns to check: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "\n",
      "=======================================================\n",
      "\n",
      " AAPL:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " AMZN:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " GOOG:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " META:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " MSFT:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n",
      "\n",
      " NVDA:\n",
      "   Total columns: 6\n",
      "   Columns: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume']\n",
      "    ALL REQUIRED COLUMNS PRESENT\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CHECK REQUIRED COLUMNS FOR ALL STOCKS\n",
    "# =============================================================================\n",
    "\n",
    "print(\" CHECKING REQUIRED COLUMNS FOR ALL STOCKS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "print(\"Required columns to check:\", required_columns)\n",
    "print(\"\\n\" + \"=\"*55)\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n {stock_name}:\")\n",
    "    print(f\"   Total columns: {len(df.columns)}\")\n",
    "    print(f\"   Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Check for missing required columns\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"    MISSING COLUMNS: {missing_columns}\")\n",
    "        \n",
    "        # Try to find and map alternative column names\n",
    "        column_mapping = {\n",
    "            'OPEN': 'Open', 'HIGH': 'High', 'LOW': 'Low', \n",
    "            'CLOSE': 'Close', 'VOLUME': 'Volume'\n",
    "        }\n",
    "        \n",
    "        mappings_made = []\n",
    "        for alt_name, std_name in column_mapping.items():\n",
    "            if alt_name in df.columns and std_name not in df.columns:\n",
    "                df[std_name] = df[alt_name]\n",
    "                mappings_made.append(f\"{alt_name}→{std_name}\")\n",
    "        \n",
    "        if mappings_made:\n",
    "            print(f\"    MAPPED: {', '.join(mappings_made)}\")\n",
    "            \n",
    "        # Check again after mapping\n",
    "        still_missing = [col for col in required_columns if col not in df.columns]\n",
    "        if still_missing:\n",
    "            print(f\"    STILL MISSING: {still_missing}\")\n",
    "        else:\n",
    "            print(f\"    ALL REQUIRED COLUMNS NOW PRESENT\")\n",
    "    else:\n",
    "        print(f\"    ALL REQUIRED COLUMNS PRESENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f2378",
   "metadata": {},
   "source": [
    "4. ENSURE REQUIRED COLUMNS EXIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2bfb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CHECKING REQUIRED COLUMNS\n",
      "===================================\n",
      "\n",
      "AAPL:\n",
      "   All required columns present\n",
      "\n",
      "AMZN:\n",
      "   All required columns present\n",
      "\n",
      "GOOG:\n",
      "   All required columns present\n",
      "\n",
      "META:\n",
      "   All required columns present\n",
      "\n",
      "MSFT:\n",
      "   All required columns present\n",
      "\n",
      "NVDA:\n",
      "   All required columns present\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENSURE REQUIRED COLUMNS EXIST\n",
    "# =============================================================================\n",
    "\n",
    "print(\" CHECKING REQUIRED COLUMNS\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n{stock_name}:\")\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"   Missing: {missing_columns}\")\n",
    "        \n",
    "        # Try to find alternative column names\n",
    "        column_mapping = {\n",
    "            'OPEN': 'Open', 'HIGH': 'High', 'LOW': 'Low', \n",
    "            'CLOSE': 'Close', 'VOLUME': 'Volume'\n",
    "        }\n",
    "        \n",
    "        for alt_name, std_name in column_mapping.items():\n",
    "            if alt_name in df.columns and std_name not in df.columns:\n",
    "                df[std_name] = df[alt_name]\n",
    "                print(f\"  Mapped {alt_name} → {std_name}\")\n",
    "    else:\n",
    "        print(f\"   All required columns present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649550e6",
   "metadata": {},
   "source": [
    "5. PREPARE DATA FOR ALL STOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58a72658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PREPARING DATA FOR ALL STOCKS\n",
      "=============================================\n",
      "\n",
      " Preparing AAPL:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing AMZN:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing GOOG:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing META:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing MSFT:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " Preparing NVDA:\n",
      "    Date converted to datetime\n",
      "    Data sorted by date\n",
      "\n",
      " PREPARATION SUMMARY:\n",
      "   • AAPL: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   • AMZN: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   • GOOG: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   • META: 2,923 rows, 0 removed, 2012-05-18 to 2023-12-29\n",
      "   • MSFT: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n",
      "   • NVDA: 3,774 rows, 0 removed, 2009-01-02 to 2023-12-29\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PREPARE DATA FOR ALL STOCKS\n",
    "# =============================================================================\n",
    "\n",
    "print(\" PREPARING DATA FOR ALL STOCKS\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "preparation_summary = {}\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n Preparing {stock_name}:\")\n",
    "    \n",
    "    # Make a copy to avoid modifying original\n",
    "    df_prepared = df.copy()\n",
    "    \n",
    "    # 1. Convert Date column to datetime\n",
    "    if 'Date' in df_prepared.columns:\n",
    "        df_prepared['Date'] = pd.to_datetime(df_prepared['Date'])\n",
    "        print(f\"    Date converted to datetime\")\n",
    "    elif 'DATE' in df_prepared.columns:\n",
    "        df_prepared['Date'] = pd.to_datetime(df_prepared['DATE'])\n",
    "        print(f\"    DATE converted to Date datetime\")\n",
    "    else:\n",
    "        print(f\"     No Date column found\")\n",
    "    \n",
    "    # 2. Sort by date (oldest to newest)\n",
    "    if 'Date' in df_prepared.columns:\n",
    "        df_prepared = df_prepared.sort_values('Date').reset_index(drop=True)\n",
    "        print(f\"    Data sorted by date\")\n",
    "    \n",
    "    # 3. Remove rows with missing required data\n",
    "    initial_rows = len(df_prepared)\n",
    "    df_prepared = df_prepared.dropna(subset=required_columns)\n",
    "    final_rows = len(df_prepared)\n",
    "    \n",
    "    rows_removed = initial_rows - final_rows\n",
    "    if rows_removed > 0:\n",
    "        print(f\"    Removed {rows_removed} rows with missing data\")\n",
    "    \n",
    "    # 4. Update the stock data with prepared DataFrame\n",
    "    stock_data[stock_name] = df_prepared\n",
    "    \n",
    "    # Store summary\n",
    "    preparation_summary[stock_name] = {\n",
    "        'initial_rows': initial_rows,\n",
    "        'final_rows': final_rows,\n",
    "        'rows_removed': rows_removed,\n",
    "        'date_range': f\"{df_prepared['Date'].min().strftime('%Y-%m-%d')} to {df_prepared['Date'].max().strftime('%Y-%m-%d')}\" if 'Date' in df_prepared.columns else 'N/A'\n",
    "    }\n",
    "\n",
    "print(f\"\\n PREPARATION SUMMARY:\")\n",
    "for stock_name, summary in preparation_summary.items():\n",
    "    print(f\"   • {stock_name}: {summary['final_rows']:,} rows, {summary['rows_removed']} removed, {summary['date_range']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bac9f5",
   "metadata": {},
   "source": [
    "6. FINAL DATA QUALITY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d10a3264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL DATA QUALITY REPORT\n",
      "========================================\n",
      "\n",
      " STOCKS READY FOR ANALYSIS: 6\n",
      "\n",
      "==================================================\n",
      " AAPL - DATA QUALITY REPORT\n",
      "==================================================\n",
      "• Total trading days: 3,774\n",
      "• Date range: 2009-01-02 to 2023-12-29\n",
      "• Time span: 5474 days\n",
      "• Missing values: 0\n",
      "• Price statistics:\n",
      "  - Open: $53.80 (avg), $2.38-$196.17 (range)\n",
      "  - High: $54.38 (avg), $2.46-$197.75 (range)\n",
      "  - Low: $53.25 (avg), $2.35-$195.16 (range)\n",
      "  - Close: $53.84 (avg), $2.35-$196.26 (range)\n",
      "• Volume: 264,063,974 (avg shares per day)\n",
      "• Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " AMZN - DATA QUALITY REPORT\n",
      "==================================================\n",
      "• Total trading days: 3,774\n",
      "• Date range: 2009-01-02 to 2023-12-29\n",
      "• Time span: 5474 days\n",
      "• Missing values: 0\n",
      "• Price statistics:\n",
      "  - Open: $59.42 (avg), $2.43-$187.20 (range)\n",
      "  - High: $60.12 (avg), $2.51-$188.65 (range)\n",
      "  - Low: $58.67 (avg), $2.38-$184.84 (range)\n",
      "  - Close: $59.41 (avg), $2.42-$186.57 (range)\n",
      "• Volume: 91,851,835 (avg shares per day)\n",
      "• Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " GOOG - DATA QUALITY REPORT\n",
      "==================================================\n",
      "• Total trading days: 3,774\n",
      "• Date range: 2009-01-02 to 2023-12-29\n",
      "• Time span: 5474 days\n",
      "• Missing values: 0\n",
      "• Price statistics:\n",
      "  - Open: $50.75 (avg), $7.13-$150.83 (range)\n",
      "  - High: $51.29 (avg), $7.41-$151.07 (range)\n",
      "  - Low: $50.25 (avg), $6.99-$148.87 (range)\n",
      "  - Close: $50.78 (avg), $6.99-$149.68 (range)\n",
      "• Volume: 61,230,955 (avg shares per day)\n",
      "• Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " META - DATA QUALITY REPORT\n",
      "==================================================\n",
      "• Total trading days: 2,923\n",
      "• Date range: 2012-05-18 to 2023-12-29\n",
      "• Time span: 4242 days\n",
      "• Missing values: 0\n",
      "• Price statistics:\n",
      "  - Open: $156.65 (avg), $17.97-$379.34 (range)\n",
      "  - High: $158.69 (avg), $18.16-$381.98 (range)\n",
      "  - Low: $154.69 (avg), $17.44-$376.49 (range)\n",
      "  - Close: $156.73 (avg), $17.62-$379.84 (range)\n",
      "• Volume: 30,606,153 (avg shares per day)\n",
      "• Memory usage: 0.13 MB\n",
      "\n",
      "==================================================\n",
      " MSFT - DATA QUALITY REPORT\n",
      "==================================================\n",
      "• Total trading days: 3,774\n",
      "• Date range: 2009-01-02 to 2023-12-29\n",
      "• Time span: 5474 days\n",
      "• Missing values: 0\n",
      "• Price statistics:\n",
      "  - Open: $102.42 (avg), $11.20-$378.83 (range)\n",
      "  - High: $103.44 (avg), $11.51-$379.36 (range)\n",
      "  - Low: $101.37 (avg), $10.95-$373.30 (range)\n",
      "  - Close: $102.46 (avg), $11.16-$377.78 (range)\n",
      "• Volume: 38,957,537 (avg shares per day)\n",
      "• Memory usage: 0.17 MB\n",
      "\n",
      "==================================================\n",
      " NVDA - DATA QUALITY REPORT\n",
      "==================================================\n",
      "• Total trading days: 3,774\n",
      "• Date range: 2009-01-02 to 2023-12-29\n",
      "• Time span: 5474 days\n",
      "• Missing values: 0\n",
      "• Price statistics:\n",
      "  - Open: $6.79 (avg), $0.17-$50.18 (range)\n",
      "  - High: $6.92 (avg), $0.17-$50.52 (range)\n",
      "  - Low: $6.67 (avg), $0.16-$49.39 (range)\n",
      "  - Close: $6.80 (avg), $0.17-$50.38 (range)\n",
      "• Volume: 523,075,307 (avg shares per day)\n",
      "• Memory usage: 0.17 MB\n",
      "\n",
      "  All stock data loaded and prepared!\n",
      "   • 6 stocks ready for technical analysis\n",
      "   • Required columns verified: ['Open', 'High', 'Low', 'Close', 'Volume']\n",
      "   • Data cleaned and sorted\n",
      "   • Ready for next step: Technical Indicators\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "#  FINAL DATA QUALITY REPORT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"FINAL DATA QUALITY REPORT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "print(f\"\\n STOCKS READY FOR ANALYSIS: {len(stock_data)}\")\n",
    "\n",
    "for stock_name, df in stock_data.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" {stock_name} - DATA QUALITY REPORT\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(f\"• Total trading days: {len(df):,}\")\n",
    "    \n",
    "    if 'Date' in df.columns:\n",
    "        print(f\"• Date range: {df['Date'].min().strftime('%Y-%m-%d')} to {df['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "        date_range_days = (df['Date'].max() - df['Date'].min()).days\n",
    "        print(f\"• Time span: {date_range_days} days\")\n",
    "    \n",
    "    # Check missing values\n",
    "    missing_counts = df[required_columns].isnull().sum()\n",
    "    total_missing = missing_counts.sum()\n",
    "    print(f\"• Missing values: {total_missing}\")\n",
    "    \n",
    "    # Price statistics\n",
    "    print(f\"• Price statistics:\")\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        if col in df.columns:\n",
    "            print(f\"  - {col}: ${df[col].mean():.2f} (avg), ${df[col].min():.2f}-${df[col].max():.2f} (range)\")\n",
    "    \n",
    "    if 'Volume' in df.columns:\n",
    "        print(f\"• Volume: {df['Volume'].mean():,.0f} (avg shares per day)\")\n",
    "    \n",
    "    print(f\"• Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "print(f\"\\n  All stock data loaded and prepared!\")\n",
    "print(f\"   • {len(stock_data)} stocks ready for technical analysis\")\n",
    "print(f\"   • Required columns verified: {required_columns}\")\n",
    "print(f\"   • Data cleaned and sorted\")\n",
    "print(f\"   • Ready for next step: Technical Indicators\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393499e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
